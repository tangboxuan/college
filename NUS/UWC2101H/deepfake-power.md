**_How Deepfake Technology Disrupts Decision-Making in Democratic Political Processes_**

16 November 2020

**Introduction**  

Deepfake is an emergent technology which allows anyone to harness the power of deep learning artificial intelligence to create altered media, which are realistic enough to be passed off as originally captured. Previous methods of media alteration were tedious manual processes of cutting and stitching together existing media, whereas Deepfake works by the automated transposing of any individual’s likeliness onto an existing media. This can be applied politically to push false narratives and ultimately distort collective political sentiments. People make decisions based on their values and knowledge. New information, especially ones that illustrate how certain politics aligns or contradicts with their values, possibly leads them to arrive at different political stances. When viewers of Deepfake fall prey to misinformation, this false information is also factored into the decision-making process. Such political misinformation can therefore affect voters’ political decisions, and ultimately their choice of vote. When political sentiments of voters are no longer grounded on facts but on the narratives of others, the fundamental concept of democracy is at stake.  

This paper explores how Deepfake, fuelled by social media, disrupts decision-making in democratic political processes. In his book “Trust in Numbers”, scientific historian Theodore M. Porter (1995) examines how in the process of producing statistics, those in power are able to influence how the data is represented and perceived. In my paper, I will draw on Porter’s ideas on power and contextualise it as the ability to influence how political facts and reality are represented and perceived. I will also draw on another aspect of power that Michel Foucault (1980) had outlined in his writing “Power/Knowledge”, that power is a function of knowledge. I will argue how individuals who weaponize Deepfake politically and the social media companies who spread them are empowered as they alter and control the perception of reality of those who view Deepfake videos. At the same time, these viewers are disempowered when Deepfake causes them to doubt facts.  

**Empowering individuals who weaponize Deepfake politically**

Deepfake technology empowers individuals who use them in nefarious ways by democratising the ability to alter media footage. The history of altering media stretches back long before the invention of computers. The earliest popularly known case of photo manipulation was in the 1860s, when Abraham Lincoln’s head was juxtaposed onto John Calhoun’s body to create one of Lincoln’s iconic portraits ([Figure 1](https://www.nydailynews.com/resizer/wWq0GGJcVqLZh3PF5eqdC7CLSFo=/800x562/top/arc-anglerfish-arc2-prod-tronc.s3.amazonaws.com/public/XVDBIIHOZOES7YPH6EN5LY2ADA.jpg)). The emergence of computers then enabled video manipulation. In 1994’s Forrest Gump, filmmakers edited footage of John F. Kennedy such that his mouth movements and speech matched with the movie script. While such manipulation was long possible, it was a resource-intensive task that took time, skill and money (O’ Sullivan, 2019). These manipulations were limited to only the few who had access to such resources. By capitalising on the explosion in computational power, the Deepfake software uses artificial intelligence to automate the entire process to produce doctored media in mere minutes without any editing skill required. Now, anyone with a modern computer is empowered to produce altered photos and video footages in large quantities to misrepresent facts.  

These digitally altered media footage can then be weaponised politically. The world of politics is no stranger to the use of altered media. Joseph Stalin was known for his commitment to cutting those that fell out of favour with him out of historical photographs in an attempt to erase them from collective memory (Blakemore, 2018). In 2019, President Donald Trump retweeted a doctored video portraying Nancy Pelosi unprofessionally by depicting her stammering drunkenly through a speech (Wagner, 2019). Deepfake is the latest addition to the arsenal of tools to alter media. The danger lies in not only the speed and ease of altering media, but also that the result is realistic to the point that people cannot distinguish Deepfaked photos and videos from originally captured ones. This allows individuals to use Deepfake to produce faux video “evidence” on demand to strengthen any claim of choice. With supporting “evidence”, these claims will be more convincing in misleading more people. Possible applications of Deepfake are in portraying politicians saying or doing things they did not actually say or do, to push certain political narratives. Deepfake then enables any individual to become more capable of politically misleading others to ultimately distort political sentiments.  

Social media platforms then aid these individuals by disseminating their false narratives. This spread can be attributed to both social media companies and users. Social media companies are constantly seeking content that lures users to spend more time on their platforms to increase their advertisement revenue. These falsified videos tend to have a disruptive and attention-catching nature which feeds into their algorithms, causing it to spread widely to reach a large audience.  Social media users contribute to its spread by further sharing these Deepfake videos beyond what the algorithm already does, with some even sharing despite already knowing that the media in question is an inaccurate portrayal of reality. A survey on social media usage in the United Kingdom found that 42.8% of news sharers admitted to sharing inaccurate information, with 40.4% of them continuing to do so despite knowing the information was made up (Chadwick & Vaccari, 2019). This further compounds the danger of Deepfake since humans in general are more likely to trust content coming from others they know or interact with, seeing that such content has passed a barrier of social validation (Welch et. al., 2007). When viewers go on to share these misleading videos, not only does it expose more users to the content, it also increases the believability of the content among their social networks leading to more people being deceived. Therefore, through a culmination of algorithmic favouritism and the behaviour of its users, Deepfake videos are able to carry their message across to a large audience on social media to deceive more people of the truth.  

Those who are deceived by these Deepfake videos will then confuse the doctored media with real events. Individuals who weaponize Deepfake politically to push false narratives and convert others to their way of thinking are therefore empowered when they shift how others perceive political reality, which is one aspect of power as defined by Porter. Since social media enables Deepfake to have such an extensive reach and influence, this empowerment of individuals is by no means to be underestimated.  

**Empowering social media companies**

The extent of these individuals’ empowerment relies a large part on the existing influence social media has over the political process. This influence stems from the amount of time the general public spends on social media platforms. Capitalising on this fact and recognising it as an effective means to spread their message, political actors then take to social media en masse to further their cause. The influx of political activity has turned these platforms into forums for political information exchange, shaping not only how the general public gets informed but also how they participate in politics (Gainous & Wagner, 2014). These platforms supply an abundance of voters who already view social media as a source of political information and who actively engage with political content they encounter. Deepfake latches onto this already established system to achieve its results.  

Deepfake in turn further amplifies the existing political influence of social media companies by giving them the power to make consequential decisions regarding how Deepfake is spread and represented. Deepfake propagates partly due to how they are preferentially selected by algorithms in the first place, but social media companies can also tweak these algorithms at will to either further increase or to stem their spread. Furthermore, even when users on social media share Deepfake with their social networks, the companies have the ultimate authority over how these posts are represented – perhaps with a disclaimer claiming the video is false – or if they are even allowed to remain on their platforms. What sets Deepfakes apart is how the attachment of believable evidence makes them that much more compelling in shaping users’ political thoughts. Since Deepfake can achieve greater influence, the ability to control its spread and representation becomes more impactful than controlling other forms of fake news. Using the aspect of power as outlined by Porter, social media companies are empowered when they can decide how Deepfake videos are represented on the platforms and influence the extent that Deepfake affects the perception of political reality by social media users.  

Deepfake further empowers social media companies by providing a means to exercise the data they have amassed on users. Social media companies can construct detailed personal profiles of its users from the immense data collected. These profiles can be used to pinpoint specific political trigger points that are likely to sway a user’s opinion on  a political matter. Social media companies then know what specific content is required to shift their users’ perception of political reality and push their thinking in a certain direction. Compared to before, Deepfake refines this ability by supplying the specific content as required. Since they can be easily produced, a plethora of Deepfake videos can be generated with each one touching on a specific trigger to be used on a certain target group. This microtargeting allows for even more effective influence over a social media user’s perception of political reality and therefore political inclination. Deepfake therefore allows the possession of users’ data that social media companies have to further empower said companies when this data can be utilised to become even more effective at shifting the perception of political reality of their users.

**Disempowering the general public by confusing facts**

Deepfake also disempowers the general public as a whole when it weakens the strength of photo and video evidence in demonstrating facts. The two main ways of ascertaining the facts of an event, such as what a politician said during a speech, are through material evidence, documentary evidence and witness testimony; the third way of establishing facts, material evidence, does not help much in such cases (Pei, 2003). Documentary evidence prevails as seeing is believing. Testimony is less convincing as it is fallible, can be made up entirely and seems less objective as it relies on the witnesses’ interpretation of facts. This was why when General Eisenhower predicted the swaths of holocaust deniers, he ordered thorough photographical documentation of concentration camps at the end of World War Two to solidify the facts of the Holocaust (Reicher, 2011). While video technology has existed for the past few decades and was used extensively by movie studios, they were clearly distinguished from reality.  On the other hand, Deepfake’s mission is to misrepresent reality. By blending in seamlessly with authentic media, people will become more uncertain of the origins of any media they encounter. Previously, people already doubted video recorded events like the moon landings (Godwin, 2019). With the existence of Deepfake, even greater doubt arises over whether any media actually depicts the facts. When doubt over the authenticity of media further increases, the strength of documentary evidence decreases and the general public’s ability to demonstrate facts is significantly weakened. Foucault holds the view that knowledge is power. Therefore, the prevalence of Deepfake weakens the ability of the public to establish facts and disempowers the general public when they become less certain in their knowledge.  

Deepfake also inadvertently undermines the credibility of information on social media at large (where they are usually spread). Deepfake’s spread on social media actually erodes its viewers’ trust in all content they come across on these platforms, even if they do not get deceived by the Deepfake media themselves (Vaccari & Chadwick, 2020). Viewers begin to start doubting even facts that they come across on social media. Deepfake does more to worsen this problem compared to other forms of misinformation again due to its convincingness, blurring the telling signs of which are real videos and altered ones. Despite being largely confined within the limits of social media, this problem should not be trivialised. Social media platforms are increasingly becoming the source of political news for many people due to its newfound status as a forum for political information exchange (Gainous & Wagner, 2013). Even when these people come across an important piece of factual political news, they may choose to reject it thinking it is just another piece of misinformation. Therefore, Deepfakes causes people who rely on social media to stay informed to lose sight of facts, disempowering them  when it erodes what they know.  

Deepfake can also lead people to believe lies when they are used to implant false memories into them. While the erosion of credibility of social media content may not affect users who are not as reliant on social media to keep updated, this effect of Deepfake can affect all its viewers. Nadine Liv and Dov Greenbaum (2020) explain that Deepfakes achieve this because people favour selecting memories that align with their preconceived notions. Even when viewers of Deepfake reject them knowing them to be false, it is still stored into their memories. Liv and Greenbaum highlight how even these sensible individuals may be duped when these memories (which align with their preconceived notions) are later evoked upon to nudge them to make certain decisions. These include political ones, an area where people hold strong opinions and ideas despite not having full knowledge of the matter (the very definition of preconceived notions). Deepfakes are more successful than other forms of doctored media again due to its hyper-realism and the volume at which it can be churned out. Therefore, Deepfake disempowers social media users when their perception of political reality is influenced in a certain way. Since a large proportion of the general public uses social media, the extent of this insidious potential is again not to be underestimated (Poushter et. al., 2018).  

Therefore, the general public is disempowered when Deepfake fundamentally attacks the general public’s knowledge of facts and their perception of reality. Having knowledge of facts is especially important in politics as the democratic process relies on voters being kept abreast of the facts. This knowledge empowers voters to make more informed political stances and choices, and more importantly, it enables the populace to keep those in power in check. For instance, tapes of Nixon attempting to stop the FBI’s investigation into the Watergate Scandal was vital in the erosion of his public approval and which resulted in his resignation (O’Sullivan, 2019). With the prevalence of Deepfakes, these videos would likely have much less political impact due to how Deepfake morphs the way the people deal with new information. The general public’s power in the political process is thus hindered when Deepfake muddles their clarity of facts.  

**Conclusion**  

Therefore, Deepfake empowers individuals who weaponize it and social media companies who spread it yet disempowers the general public who views it. However, democracies are a diverse lot and the extent of empowerment and disempowerment within each country varies according to the laws and institutional structures of each country. Countries deal with the problem of online misinformation differently; while Singapore has imposed strict laws against misinformation through the Protection from Online Falsehoods and Manipulation Act, at time of writing the United States (federally) and United Kingdom has yet to pass similar regulatory laws (Castro, 2020; Farish, 2020). The extent of empowerment and disempowerment in countries that have tough regulations against Deepfake would definitely be curtailed by the decreased exposure to Deepfake videos. Given how much social media companies are in the public’s eyes, they may not easily escape scrutiny and enforcement while individuals can more easily circumvent or go unnoticed by the law. Therefore, regulations also decrease the empowerment of individuals and social media companies to different extents.  

In democracies without regulations on the sharing of Deepfake on social media platforms, social media companies may respond according to their own company’s values and agendas. The power to control the extent of Deepfake’s influence in political decision making then lies in the hand of these companies. Do we truly trust private companies with this much power in the electoral process?  

**_Bibliography_**  

Abraham Lincoln [Photograph]. (1865). Library of Congress, Washington, D.C.. W. Pate (Author).  

Blakemore, E. (2018, April 20). How Photos Became a Weapon in Stalin's Great Purge. <https://www.history.com/news/josef-stalin-great-purge-photo-retouching>  

Castro, D. (2020, January/February). Deepfakes Are on the Rise - How Should Government Respond? <https://www.govtech.com/policy/Deepfakes-Are-on-the-Rise-How-Should-Government-Respond.html>  

Chadwick, A., & Vaccari, C. (2019). News sharing on UK social media: misinformation, disinformation, and correction. Loughborough University. <https://hdl.handle.net/2134/37720>  

Farish, K. (2020, September 4). The legal implications and challenges of deepfakes. <https://www.dacbeachcroft.com/en/gb/articles/2020/september/the-legal-implications-and-challenges-of-deepfakes/>   

Foucault, M. (1980). Power / knowledge. New York, NY: Harvester Wheatsheaf.  

Gainous, J., & Wagner, K. M. (2014). Tweeting to power: The social media revolution in American politics. Oxford University Press. doi:10.1093/acprof:oso/9780199965076.001.0001  

Godwin, R. (2019, July 10). One giant ... lie? Why so many people still think the moon landings were faked. The Guardian.  https://www.theguardian.com/  

Liv, N., & Greenbaum, D. (2020). Deep Fakes and Memory Malleability: False Memories in the Service of Fake News. AJOB Neuroscience, 11(2), 96-104. doi:10.1080/21507740.2020.1740351  

O’Sullivan, D. (2019). Deepfake videos: Inside the Pentagon’s race against Deepfake videos. CNN. https://www.cnn.com/  

Pei, C. (2003). On the Kinds of Evidence. Cass Journal of Law, (3).   

Porter, T. M. (1995). How Social Numbers Are Made Valid. In Trust in Numbers: The Pursuit of Objectivity in Science and Public Life (pp. 33–48). Princeton University Press.   

Poushter, J., Bishop, C., & Chwe, H. (2018). Social Media Use Continues to Rise in Developing Countries but Plateaus Across Developed Ones (Rep.). Washington, D.C.: Pew Research Centre.  

Reicher, H. (2011, December 14). General Eisenhower and the Documentation of the Holocaust. Speech presented at Eisenhower and the Writing of Holocaust History in Eisenhower Presidential Library and Museum, Abilene, KY.  

Vaccari, C., & Chadwick, A. (2020). Deepfakes and Disinformation: Exploring the Impact of Synthetic Political Video on Deception, Uncertainty, and Trust in News. Social Media + Society, 6(1). doi:10.1177/2056305120903408  

Wagner, J. (2019, May 24). Trump shares heavily edited video that highlights verbal stumbles by Pelosi and questions her mental acuity. The Washington Post. https://www.washingtonpost.com/  

Welch, M. R., Sikkink, D., & Loveland, M. T. (2007). The Radius of Trust: Religion, Social Embeddedness and Trust in Strangers. Social Forces, 86(1), 23-46. doi:10.1353/sof.2007.0116  
